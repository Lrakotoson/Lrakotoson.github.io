---
title: "Licence 3 MIASHS - Semester 2"
author: "LOIC RAKOTOSON, contact@loicrakotoson.com"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
    highlight: tango
    theme: default
---
****
***
# **Manipulation de données - fonctions usuelles de R**
***
****


# 1. **Données chd**

Le fichier **chd.csv** renseigne, sur n = 100 individus, l’âge de l’individu (variable age) et le fait qu’il soit porteur d’une maladie ou non (variable nommée **chd**, codée 1 pour oui, 0 pour non). On s’intéresse à l’influence de l’âge sur le fait d’être porteur ou non de la maladie.
L’objet de l’exercice est en particulier de former des classes d’âge (sous forme d’intervalles contigus) et de
calculer la proportion de malades dans chacune des classes. On cherche aussi à représenter graphiquement la situation et les résultats obtenus.

Plus généralement, ce type de données peut être utilisé pour essayer de voir si la variable âge (quantitative) permet d’expliquer l’appartenance à l’une des modalités d’une variable binaire (ici variable chd de modalités 1 ou 0). C’est un problème typique de la régression dite logistique. Nous ne rentrons pas ici dans la méthode. Cependant, précisons pour information que la dernière question consiste à appliquer les résultats d’un modèle
logistique aux données.

## 1.1 Exploitation des données
1. Importer et calculer le résumé des données.
```{r}
donnees <- read.csv("chd.csv", sep = ";")
summary(donnees)
```

2. Calculer la moyenne de la variable chd. A quoi correspond cette valeur ?
```{r}
mean(donnees$chd)
```

3. La variable chd est interprétée comme quantitative : ajouter aux données une colonne appelée *chd.quali* qui contient la conversion de la variable chd en facteur (fonction **factor()**). Recalculer le résumé des données et retrouver ainsi que 43% des individus sont porteurs de la maladie.
```{r}
chd.quali = factor(donnees$chd, levels = c(0,1), labels = c("sain", "malade"))
donnees = cbind(donnees, chd.quali)
summary(donnees)
```

4. Calculer la moyenne d’âge d’un individu malade, d’un individu sain.
```{r}
by(donnees$age,donnees$chd.quali,mean)
```

5. On se propose de former des classes d’âge puis de calculer la proportion d’individus malades dans chaque classe.
(a) Utiliser la fonction **cut()** pour regrouper les valeurs d’âge dans les intervalles suivants : <br>
**[20, 29] &ensp;]29, 34] &ensp;]34, 39] &ensp;]39, 44] &ensp;]44, 49] &ensp;]49, 45] &ensp;]54, 59] &ensp;]59, 69]**

Indications :<br>
+ On s’assurera que tous les individus sont bien associés.<br>
+ On pourra, comme à la question 2, créer une colonne supplémentaire dans le jeu de données, appelée par exemple *age.quali*, qui recevra la classe d’appartenance de chaque individu.
```{r}
age.quali = cut(donnees$age, b=c(20,29,34,39,44,49,54,59,69), right = T, include.lowest = T)
donnees = cbind(donnees, age.quali)
by(donnees$chd, donnees$age.quali, mean) #moyenne de malades par age.quali
```

(b) Calculer la proportion d’individus malades dans chaque classe d’âge.
```{r}
table(donnees$chd.quali, donnees$age.quali) #effectifs par age.quali
```

## 1.2 Graphe
1. Représenter dans un plan les données d’âge en abscisse et celle de la variable quantitative chd en ordonnée, sans oublier de légender les axes.
```{r}
plot(x = donnees$age, y = donnees$chd, xlab = "age", ylab = "chd")
```

2. Ajouter par un trait horizontal en pointillés, la proportion des individus malades (sur l’ensemble des données).
```{r}
plot(x = donnees$age, y = donnees$chd, xlab = "age", ylab = "chd") # Question 1
abline(h = mean(donnees$chd), col ="blue", lty = "dotted")
```

3. On souhaite ajouter à̀ ce graphe une représentation de la proportion d’individus malades par classe d’âge. Pour cela, on pourra tracer des segments horizontaux de couleur rouge, de bornes correspondantes aux extrémités des classes d’âge, et les placer à la hauteur correspondant à la proportion d’individus malades dans la classe.
```{r}
plot(x = donnees$age, y = donnees$chd, xlab = "age", ylab = "chd") # Question 1
abline(h = mean(donnees$chd), col ="blue", lty = "dotted") # Question 2
##proportion de malade par classe d'age
segments(x0 = c(20,29,34,39,44,49,54,59),
         y0 = c(by(donnees$chd, donnees$age.quali, mean)),
         x1 = c(29,34,39,44,49,54,59,69),
         y1 = c(by(donnees$chd, donnees$age.quali, mean)),
         col = "red")
```

4. On considère la fonction f : R → [0, 1] telle que
$$f(x)=\frac{exp(B_1 + B_2 x)} {1 + exp(B_1 + B_2 x)}$$
Représenter sur le graphe la courbe de f pour $B_1$= −5, 30 et $B_2$ = 0, 11. Cette fonction est le résultat de l’application d’un modèle logistique aux données : $f(x)$ donne une estimation de la probabilité qu’un individu soit porteur de la maladie à l'âge x.
```{r}
plot(x = donnees$age, y = donnees$chd, xlab = "age", ylab = "chd") # Question 1
abline(h = mean(donnees$chd), col ="blue", lty = "dotted") # Question 2
segments(x0 = c(20,29,34,39,44,49,54,59), y0 = c(by(donnees$chd, donnees$age.quali, mean)), x1 = c(29,34,39,44,49,54,59,69), y1 = c(by(donnees$chd, donnees$age.quali, mean)), col = "red") #Question 3

#_________________________________________________________________
x <- seq(min(donnees$age), max(donnees$age))
lines(x,(exp(-5.3 + 0.11*x))/(1+exp(-5.3 + 0.11*x)), col = "blue")
```


# 2. **Température de surface de l'océan**
Vous disposez de 2 jeux de données de températures de surface de l’océan (en degré Celsius) : données observées et données modélisées. Elles se trouvent dans les fichiers **observations.csv** et **modelise.csv** respectivement.
Ces fichiers contiennent des données SST pour 5 régions océaniques proches de la Bretagne : dans la Manche au nord (Manche Nord), et au sud (Manche Sud), en Mer d’Iroise au large (Mer Iroise Zone Large), ou près de la côte (Mer Iroise Zone Côtière) et enfin dans l’Atlantique au large des côtes du Morbihan (Plateau Armoricain).
Ces régions sont localisées sur la figure ci-dessous :<br>
![Température océan](temperature_ocean.jpg){width=50%}

**Données observées** Chaque groupe possède les données de Mer Iroise Zone Large et celles d’une autre région. Il y a 5 colonnes :
<ul>
<li> année,</li>
<li>mois (numéroté de 1 à 12),</li>
<li> jour (numéroté de 1 à 31),</li>
<li> SST pour Mer Iroise Zone Large</li>
<li> SST de l’autre région</li>
</ul>
Ce sont des données satellites à 5km de résolution moyennée spatialement, au pas de temps journalier de 1986 à 2013.

**Données modélisées** Ce sont des données issues de 3 modèles : CNRM ; MPILR MPIMR à différentes résolutions. Ce sont des valeurs, moyennées sur quelques points qui correspondent à la Mer Iroise Zone Large dans chacun des modèles. Les données sont au pas de temps journalier de 1980 à 2005.


##2.1 Importation et préparation des données
1. Importer dans R les données. On conservera les colonnes jour, mois et année au format numérique.
```{r}
observations <- read.csv2("observations.csv")
modelise <- read.csv2("modelise.csv")
```

2. Dans les données d’observations, changer le nom des deux dernières colonnes : *SST MerIroiseZL* en region1 et *SST Plateau Armor* en region2.
```{r}
names(observations) #pour connaitre les noms de colonnes
names(observations)[4] <- "region1"
names(observations)[5] <- "region2"
names(observations) #pour vérifier
```

3. Dans les données modélisées, changer le nom des trois dernières colonnes en les nommant : model1, model2 et model3.
```{r}
names(modelise)
names(modelise)[(ncol(modelise)-2):ncol(modelise)] <- c("model1","model2","model3")
names(modelise)
```

4. Ajouter aux deux data frame de données une colonne intitulée date résultant de la chaîne de caractères obtenue en “collant” les informations d’année, de mois, de jour, dans cet ordre.<br>
**NB. La date servira de clé de jointure pour la fusion des tableaux ; il est préférable que le nom de la variable date soit identique dans les deux data frame**
```{r}
modelise$date <- paste(modelise$jour, modelise$mois, modelise$annee, sep = "/")
observations$date <- paste(observations$jour, observations$mois, observations$annee, sep = "/")
```

5. Dans chaque data frame créer une variable intitulée saison, à 4 modalités,
<ul>
<li>H associée aux mois de décembre, janvier et février</li>
<li>P associée aux mois de mars, d’avril et mai</li>
<li>E associée aux mois de juin, juillet et août</li>
<li>A associée aux mois de septembre, octobre et novembre</li>
</ul>
```{r}
#Méthode 1 ___________ Observations Data
observations$saison <- factor(observations$mois, labels = c("H","H",
                                                            "P","P","P",
                                                            "E","E","E",
                                                            "A","A","A",
                                                            "H"))
```

```{r}
#Méthode 2 ___________ Modelise Data
modelise$saison <- rep("default",nrow(modelise))
modelise$saison[modelise$mois==12 | modelise$mois== 1 | modelise$mois== 2] <- "H"
modelise$saison[modelise$mois== 3 | modelise$mois== 4 | modelise$mois== 5] <- "P"
modelise$saison[modelise$mois== 6 | modelise$mois== 7 | modelise$mois== 8] <- "E"
modelise$saison[modelise$mois== 9 | modelise$mois==10 | modelise$mois==11] <- "A"
modelise$saison <- factor(modelise$saison)
```

##2.2 Fusion des tableaux
L’opération de fusion de tableau est toujours une opération délicate : il faut avancer avec prudence et autant que possible mettre en place quelques procédures de vérifications.
Les dates de mesures ne sont pas identiques dans les deux tableaux. Cependant, les deux tableaux possèdent des dates communes. Nous souhaitons créer un tableau qui comporte toutes les colonnes (i.e. les colonnes des deux tableaux) avec comme informations les lignes correspondant aux dates communes de mesures.


1. L’opérateur **%in%** qui s’applique à deux vecteurs **A** et **B** selon la syntaxe __A *%in%* B__ renvoie un vecteur de booléens, de longueur identique à la longueur du vecteur **A**, précisant l’appartenance ou non de chaque coordonnée de **A** à l’ensemble défini par les coordonnées de **B**.
```{r}
A <- c(1,2,5,30)
B <- 1:10
A %in% B
B %in% A
```

2. Déterminer le nombre de lignes dans chacun des deux tableaux. Utiliser l’opérateur défini en question précédente pour déterminer le nombre de dates communes dans les deux tableaux.
```{r}
nrow(modelise) #nombre de lignes dans modelise
nrow(observations) #nombre de lignes dans observations

table(modelise$date %in% observations$date) #même nombre de TRUE que:
table(observations$date %in% modelise$date)
```

3. Faire fusionner les deux tableaux dans un tableau résultat appelé **tab.merge** en utilisant date comme clé de jointure. Assurez-vous que le nombre de lignes est bien celui attendu.
```{r}
tab.merge <- merge(modelise,observations[,-c(1:3,7)],by="date")
# [,-c(1:3,7)] supprime les redondances des trois premières colonnes (jours, mois, années) et de la septième (saison)
```

4. Identifier quelques lignes des deux tableaux initiaux qui doivent être présentes dans le tableau fusionné. En revenant aux données, vérifier, sur quelques individus, que le tableau fusionné a pris les bonnes informations.

5. Certaines colonnes du tableau fusionné sont redondantes : vérifiez-le puis supprimez les redondances.
```{r}
#Cette correction a été faite à la question 3
#La suppression de la colonne jour.y de tab.merge s'effectue de la manière suivante:
tab.merge$jour.y <- NULL 
```


##2.3 Statistiques descriptives
Nous travaillons bien sûr désormais sur le tableau fusionné.

1. Présenter les boxplots des 3 variables modélisées toutes dates confondues.
```{r}
boxplot(tab.merge$model1, tab.merge$model2, tab.merge$model3,
        names = c("M1", "M2", "M3"), ylab = "température")
```

2. Présenter les boxplots des 3 variables modélisées, saison par saison.
```{r}
boxplot(model1~saison, data = tab.merge, ylab = "température") # pour le 1er modèle
```

3. Présenter les boxplots des 3 variables modélisées, mois par mois.
```{r}
boxplot(model1~mois, data = tab.merge, ylab = "température") # pour le 1er modèle
```

4. Calculer les résumés numériques classiques des variables modélisées toutes dates confondues.
```{r}
summary(tab.merge$model1) # pour le 1er modèle
```

5. Calculer les résumés numériques classiques des variables modélisées saison par saison.
```{r}
#Méthode 1 _______by() Saison
by(tab.merge$model1, tab.merge$saison, summary) # pour le 1er modèle
```

6. Calculer les résumés numériques classiques des variables modélisées mois par mois.
```{r}
#Méthode 2 _______tapply() summary par mois
tapply(tab.merge$model1, tab.merge$mois, summary) # pour le 1er modèle
```


# 3. **Traitement de valeurs manquantes : données bebe**
Le jeu de données **bebe.txt** renseigne des variables mesurées dans une maternité, les individus sont ici les naissances (ou les bébés). Certaines données ne sont pas renseignées. Il s’agit dans cet exercice de repérer les individus pour lesquels au moins une variable n’est pas renseignée dans le but d’éliminer ces individus avant analyse.

##3.1 Importation, prise en main des données
1. Importer les données.
```{r}
bebe <- read.csv("bebe.txt", sep=";")
```

2. Calculer le résumé des données. Quelles informations donne la fonction **summary()** quant aux valeurs manquantes ?
```{r}
summary(bebe) # summary() donne le nombre de NA
```

3. Paramétrer convenablement l’appel de la fonction **mean()** de sorte à calculer la taille moyenne d’un bébé.
```{r}
mean(bebe$TailleBB, na.rm = T) # sans considérer les NA ou
mean(na.omit(bebe$TailleBB)) # en supprimant les lignes avec NA

```

##3.2 Repérage des individus non totalement renseignés
1. Combien y-a-t’il de données manquantes ?
```{r}
table(is.na(bebe)) # nombre de TRUE ou
sum(is.na(bebe)) # somme des TRUE
```

2. En combinant les fonctions **is.na()**, **which()** *(préciser le paramètre arr.ind)* et **unique()**, déterminer les individus non totalement renseignés.
```{r}
#Méthode 1____________ partie de data frame
manque <- unique( bebe [which(is.na(bebe), arr.ind = T) [,1] ,] )
```

3. Retrouver le résultat précédent au moyen d’une boucle sur les colonnes du tableau.
```{r}
#Méthode 2____________ boucle for et conditionnelle if
manque <- data.frame() # data frame de réception
for (i in 1:ncol(bebe)) {
  if ( length( which( is.na(bebe[,i]) ) ) > 0 ){
    manque <- unique( rbind( manque, bebe[ which( is.na(bebe[,i]) ),]) )
  }
}
```

##3.3 Export des données “nettoyées”
Etant donné le grand nombre d’individus concernés, les enlever serait sans trop doute trop radical. Mais pour l’exercice, nous construisons un jeu de données “nettoyé” et l’exportons.

1. Créer le tableau regroupant les individus totalement renseignés en utilisant les résultats obtenus.
```{r}
#Méthode 1____________ suppression par ligne
newBebe <- bebe[ - as.integer(row.names(manque)),]
```

2. Obtenir le même tableau de manière directe en utilisant la fonction **na.omit()**.
```{r}
#Méthode 2____________ suppression des lignes contenant NA
newBebe <- na.omit(bebe)
```

3. Exporter le tableau ainsi nettoyé au moyen de la fonction **write.table()**.
```{r eval=FALSE, include=TRUE}
write.table(newBebe, "newBebe.txt")
```
<br><br>

****
***
# **Statistique inférentielle**
***
****
# 4. **Simulation avec R**
En statistique inférentielle, on est amené à examiner les propriétés théoriques d’estimateurs (i.e. de variables aléatoires fonction des données) pour juger de leur capacité à bien estimer, dans le cadre de l’estimation paramétrique par exemple, le(s) paramètre(s) inconnu(s) de la loi postulée par le modèle.
Ainsi, si on prouve qu’un estimateur a de bonnes propriétés (consistance, faible biais, faible variance...), on a une plus grande confiance en l’estimation du paramètre, estimation qui correspond à la seule réalisation de cette variable aléatoire dont on dispose.

Cependant, étudier les propriétés de telles variables n’est pas toujours simple. En outre, dans certains cas, il peut être utile de tenter de vérifier empiriquement ces propriétés avant de se lancer dans leur étude théorique.

Le logiciel R intègre ainsi un générateur de nombres aléatoires. Plusieurs fonctions prédéfinies permettent ainsi de générer des nombres aléatoires selon la loi usuelle souhaitée. Nous les utilisons dans cette section pour illustrer deux résultats fondateurs en probabilité (Loi des grands nombres, Théorème central limite) et revenir sur le sens de quelques éléments classiques en estimation (estimation par intervalles, biais-variance...).

##4.1 Fonctions de base pour générer des nombres aléatoires
1. Commenter les instructions suivantes:<br>

fonction **sample()**
```{r}
sample(100) # Tirage sans remise de 100 nombres de 0 à 100.
table(sample(x=1:10, size=100, replace=T)) # Tirage de 100 nombres de 1 à 10 avec remise.
```

fonction **rbinom()**
```{r}
rbinom(n = 10, size = 3, prob = 0.5) # échantillon de taille 10 d'une loi binomiale B(3, 0.5)
rbinom(n = 10, size = 5, prob = 0.2) # échantillon de taille 10 d'une loi binomiale B(5, 0.2)
```

fonction **rnorm()**
```{r}
rnorm(n = 10, mean = 0, sd = 1) # échantillon de taille 10 d'une loi normale N(0, 1)
rnorm(n = 10, mean = 2, sd = 5) # échantillon de taille 10 d'une loi normale N(2, 5)
```

fonction **runif()**
```{r}
U <- runif(n = 1000, min = 0, max = 15)
hist(U, freq = F) # histogramme d'une loi uniforme d'échantillon de taille 1000
```


2. Générer des nombres aléatoires en utilisant les fonctions **rpois()** puis **rexp()**.
```{r}
rpois(n = 10, lambda = 5) # échantillon de taille 10 d'une loi Poisson P(5)
rexp(n = 10, rate = 5) # échantillon de taille 10 d'une loi exponentielle E(5)
```


3. Générer n = 1000 nombres aléatoires suivant une loi $N (0, 1)$.<br>
(a) Représenter un histogramme de la distribution des valeurs.
```{r}
valeurs <- rnorm(1000, 0, 1)
hist(valeurs, freq = F, breaks = 30)
```


(b) Au graphe précédent, ajouter la courbe de densité de la loi $N (0, 1)$ (fonctions **dnorm()** et **lines()**).
```{r}
hist(valeurs, freq = F, breaks = 30) # Question a

x <- seq(-3,3, length=100)
y <- dnorm(x,0,1)
lines(x,y,col="red")
```


(c) Représenter la fonction de répartition empirique de ces valeurs aléatoires (fonction **ecdf()**).
```{r}
Fchap <- ecdf(valeurs)
plot(x, Fchap(x), type = "l")
```


(d) Sur le même graphe, ajouter la courbe de la fonction de répartition de la loi $N (0, 1)$ (fonction **pnorm()**).
```{r}
Fchap <- ecdf(valeurs)
plot(x, Fchap(x), type = "l") #Question c

lines(x,pnorm(x,0,1), col = "blue")
```



##4.2 Génération d’échantillons
Nous venons de voir comment générer un échantillon (par définition un échantillon est aléatoire) selon une loi particulière. On est souvent intéressé par la moyenne d’un échantillon. En composant la fonction **mean()** avec les fonctions de génération des nombres aléatoires vues au-dessus, cela est très simple. Par exemple :
<br>```mean( rnorm( 10, mean=0, sd=1 ) )```<br>
On propose dans la suite de générer *K* échantillons de taille *n* selon une loi commune et calculer chacune des *K* moyennes associées, au moyen d’une boucle tout d’abord, puis de manière plus appropriée ensuite.


1. Au moyen d’une boucle.<br>
*M* recueillera les moyennes. <br>
On pose *K*=10 et *n*=10
```{r}
M <- NULL
K <- 5
n <- 10
for (i in 1:K){
  M[i] <- mean( rnorm(n,0, 1) )
}
print(M)
```


2. En combinant les fonctions **matrix()** et **apply()**.<br>
*valeurs* est un tirage d'échantillon de taille _K_ * _n_<br>
*M* est une matrice où chaque ligne correspond à un échantillon. <br>
On calcule la moyenne par ligne de la matrice.
```{r}
valeurs <- rnorm(K*n, 0,1)
M <- matrix(valeurs, K, n)
apply( M, 1, mean )
```



##4.3 Loi des grands nombres
On rappelle la **loi faible des grands nombres** :<br>
Soit (X<sub>n</sub>)<sub>n∈N </sub>une suite de variables aléatoires d’espérance commune E[X] = µ et de variance commune var(X) = σ^2^ . Alors:
$$\forall\epsilon < 0, \hspace{20pt} lim_{n\to\infty} P (|\frac{X_1+...+X_n}{n}-\mu | > \epsilon)=0$$
Autrement-dit, pour un échantillon i.i.d. (c’est le cas courant), la probabilité que la (variable aléatoire) moyenne d’échantillon s’éloigne de plus de ε de l’espérance commune E[X] converge vers 0 quand $n\to\infty$.<br>
Il ne s’agit pas ici de calculer la probabilité en question, mais d’en obtenir une valeur approchée en comptant la proportion des moyennes d’échantillon $\bar{x}=\frac{x_1+...+x_n}{n}$ telles que
$$|\bar{x}-\mu|>\epsilon$$
On prendra les $X_i$ i.i.d. selon une loi normale $\mathcal{N}(\mu, \sigma^2 )$.<br>
1. Proposer une programmation qui permettent de faire varier les constantes (µ, σ, n, ε et *K* le nombre d’échantillons) au clavier et qui compte, parmi les *K* échantillons, la proportion de ceux dont les moyennes $\bar{x}=\frac{x_1+...+x_n}{n}$ vérifient:
$$|\bar{x}-\mu|>\epsilon$$

Déclaration des constantes
```{r}
n <- 10
K <- 500
mu <- 0
sigma <- 1
epsilon <- 0.2
```


Tirage, avec une boucle, de $K$ echantillons de loi $\mathcal{N}(\mu,\sigma)$ et réception de leur moyenne dans *resultat*
```{r}
resultat <- rep(0,K)
for (i in 1:K) {
  echantillon <- rnorm( n, mean = mu, sd = sigma)
  resultat[i] <- mean(echantillon)
}
summary(resultat)
```


Calcul des pourcentages
```{r}
sum( resultat > epsilon )/K
```


2. Faire varier les constantes de sorte à illustrer la loi des grands nombres.<br>
3. Représenter graphiquement la situation.
<ul>
<li>Choix d'une grille de valeur de $n$ (ici **NN**: 10, 50, 100, 200, 500)</li>
<li>Initialisation du graphique (entre -1 et 1 sur cette grille de $n$)</li>
<li>Pour chaque valeur de $n$, tirage de $K$ = 500 echantillons dont la moyenne est calculée et représentation en *points*</li>
<li>Rajout des droites horizontales</li>
```{r}
NN <- c( 10, 50, 100, 200, 500)

plot( rep( NN, each=2 ), rep( c( -1, 1 ), length(NN) ), type="n", xlab="n", ylab="Moyenne empirique")

for (n in 1:length(NN) ) {
  resultat <- rep( 0, K )
  
  for (i in 1:K) {
    echantillon <- rnorm( NN[n], mean = mu, sd = sigma)
    resultat[i] <- mean(echantillon)
  }
  
  summary (resultat)
  points( rep( NN[n], K ), resultat, col = n ) 
}


abline(h=c(mu,mu+epsilon,mu-epsilon),col=c("black","grey70","grey70"))
```

**Remarque*** Dans cet exercice, nous admettons que la proportion des moyennes d’échantillons telles que
$|\bar{x}-\mu|>\epsilon$ est proche de $P(|\bar{X}-\mu|>\epsilon)$ . Nous l’admettons car c’est un résultat conforme à l’intuition. Cependant sa justification relève... de la loi des grands nombres...


##4.4 Théorème Central Limite
On rappelle le théorème : Soit ($X_n$) une suite de variables aléatoires i.i.d. selon une loi commune $X$ d’espérance $\mu$ et de variance $\sigma^2$ . Alors :
$$\frac{1}{\sqrt{n}}(\frac{X_1+...X_n - n\mu}{\sigma})\to_{\mathcal{L}}\mathcal{N}(0,1)\hspace{50pt}(1)$$

1. Vérifier que la variable aléatoire dans l’équation $(1)$ peut s’écrire $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$<br>
2. En pratique, pour n assez grand, par quelle loi peut-on approcher la loi de $\bar{X}$ ?<br>

<h4>Illustration avec $X$~ $\mathcal{U}_{[a,b]}$</h4>
1. Rappeler les expressions de **E[X]** et **var(X)** pour $X$~ $\mathcal{U}_{[a,b]}$<br>
2. Générer *K* moyennes d’échantillon $X_1$, . . . , $X_n$ avec les $X_i$ i.i.d. selon la loi $\mathcal{U}_{[a,b]}$.
```{r}
# Affectations paramètres
a <- 0
b <- 1
mu <- (b+a)/2
sigma <- sqrt((b-a)^2/12)
n <- 10
K <- 500

# Tirages des echantillons et calculs de moyenne
echantillon <- matrix( runif( n*K, a, b), nrow = K, ncol = n)
resultat <- apply( echantillon, 1, mean)
```

3. Sur un même graphe représenter la distribution de ces *K* moyennes d’échantillon et la distribution théorique par laquelle on peut l’approcher.
```{r}
x <- seq ( mu-3.5*sigma/sqrt(n), mu+3.5*sigma/sqrt(n), length = 1000)
y <- dnorm( x, mean = mu, sd = sigma/sqrt(n) )

hist( resultat, freq = F, main = "Illustration du TCL", xlab = expression(bar(X)), ylab = "densite")

lines( x, y, col = "red") # distribution théorique
```



##4.5 Notion d’intervalle de confiance
###Données *Nile*
Les données Nile sont disponibles sous **R**. Elles donnent la valeur du débit annuel du Nil, entre 1871 et 1970, à Assouan.

1. Quel est le débit moyen, mesuré sur ces 100 années ? Quel est l’écart-type ?
```{r}
mean(Nile) # débit moyen
sd(Nile) # écart-type
```


2. En utilisant la fonction **t.test()**, obtenir un intervalle de confiance pour le débit moyen, au niveau de confiance 95%, au niveau de confiance 99%.
```{r}
t.test(Nile, conf.level = 0.95)
t.test(Nile, conf.level = 0.99)
```


3. Vérifier que les bornes des intervalles de confiance sont données par:
$$\bar{x}\pm\frac{\hat{\sigma}}{\sqrt{n}}t_{n-1}(1-\alpha/2)$$
```{r}
#Pour un niveau de confiance à 95%
#Les bornes sont
inferieur <- mean(Nile) - (sd(Nile) * qt( 0.975, df = length(Nile) - 1) )/sqrt( length(Nile) )
superieur <- mean(Nile) + (sd(Nile) * qt( 0.975, df = length(Nile) - 1) )/sqrt( length(Nile) )
```


4. Quelles conditions supposent l’emploi de ces formules ?


<br><br><br>


****
Tu es arrivé jusqu'au boût !
